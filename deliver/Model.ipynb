{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import cv2\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "os.sys.path.append('../src')\n",
    "from helpers import resize_to_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.abspath(os.path.relpath('../data'))\n",
    "image_dir = os.path.abspath(os.path.relpath('../doc/images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPTCHA_IMAGES_FOLDER = \"../data/samples\"\n",
    "\n",
    "# initialize the data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# loop over the input images\n",
    "for image_file in paths.list_images(CAPTCHA_IMAGES_FOLDER):\n",
    "    # Load the image and convert it to grayscale\n",
    "\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Grab the labels\n",
    "    label = image_file.split(os.path.sep)[-1].split('.')[-2]\n",
    "\n",
    "    # Add the image and it's label to our training data\n",
    "    data.append(image)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(data, labels, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images(data, label):\n",
    "    # Otsu threashold\n",
    "    data_pre = []\n",
    "    for e in data:\n",
    "        ret, th = cv2.threshold(e, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        dilation = cv2.dilate(th, kernel, iterations=1)\n",
    "        erosion = cv2.erode(dilation, kernel, iterations=1)\n",
    "        data_pre.append(erosion)\n",
    "    \n",
    "    # K-means\n",
    "    data_pts = []\n",
    "    for e in data_pre:\n",
    "        data_pts.append(np.where(e == 0))\n",
    "    data_pts = np.array(data_pts)\n",
    "    \n",
    "    X = []\n",
    "    thres = 3\n",
    "    for e in data_pts:\n",
    "        x = (np.vstack((e[1],np.flip(e[0])))).T\n",
    "        l = []\n",
    "        # Discard columns with less than thres points\n",
    "        for i in range(200):\n",
    "            if len(x[x[:,0] == i]) > thres:\n",
    "                for f in x[x[:,0] == i]:\n",
    "                    l.append(f)\n",
    "        x = np.array(l)\n",
    "        X.append(x)\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # Projection in x-axis\n",
    "    X_proj = [x[:,0].reshape(-1,1) for x in X]\n",
    "    \n",
    "    # Find clusters in projected data\n",
    "    y_kmeans_proj = []\n",
    "    centers_kmeans_proj = []\n",
    "    for i, x in enumerate(X_proj):\n",
    "        kmeans = KMeans(n_clusters=5)#, init=np.array([(i*200/6.0, 25) for i in range(1,6)]))\n",
    "        kmeans.fit(x)\n",
    "        centers_kmeans_proj.append(kmeans.cluster_centers_)\n",
    "        y_kmeans_proj.append(kmeans.predict(x))\n",
    "\n",
    "    centers = [np.sort(e, axis=0) for e in centers_kmeans_proj]\n",
    "    data_chars = []\n",
    "    for i, e in enumerate(data_pre):\n",
    "        chars = []\n",
    "        for j in range(5):\n",
    "            chars.append(e[:,int(centers[i][j]-21):int(centers[i][j]+21)])\n",
    "        data_chars.append(chars)\n",
    "        \n",
    "    return data_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_train_dir = '../data/letters/train'\n",
    "\n",
    "data_chars = create_images(X_train, y_train)\n",
    "\n",
    "if not(os.path.isdir(''.join((letters_train_dir)))):\n",
    "    os.mkdir(''.join((letters_train_dir)))\n",
    "\n",
    "for i,e in enumerate(data_chars):\n",
    "    for j in range(5):\n",
    "        if not(os.path.isdir(''.join((letters_train_dir,'/',y_train[i],'/')))):\n",
    "            os.mkdir(''.join((letters_train_dir,'/',y_train[i],'/')))\n",
    "        cv2.imwrite(''.join((letters_train_dir,'/',y_train[i],'/',str(j),'-',y_train[i][j],'.png')),e[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_test_dir = '../data/letters/test'\n",
    "\n",
    "data_chars_test = create_images(X_test, y_test)\n",
    "\n",
    "if not(os.path.isdir(''.join((letters_test_dir)))):\n",
    "    os.mkdir(''.join((letters_test_dir)))\n",
    "\n",
    "for i,e in enumerate(data_chars_test):\n",
    "    for j in range(5):\n",
    "        if not(os.path.isdir(''.join((letters_test_dir,'/',y_test[i],'/')))):\n",
    "            os.mkdir(''.join((letters_test_dir,'/',y_test[i],'/')))\n",
    "        cv2.imwrite(''.join((letters_test_dir,'/',y_test[i],'/',str(j),'-',y_test[i][j],'.png')),e[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTER_IMAGES_FOLDER = letters_train_dir\n",
    "\n",
    "# initialize the data and labels\n",
    "data_l_train = []\n",
    "labels_l_train = []\n",
    "\n",
    "# loop over the input images\n",
    "for image_file in paths.list_images(LETTER_IMAGES_FOLDER):\n",
    "    # Load the image and convert it to grayscale\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize the letter so it fits in a 28x28 pixel box\n",
    "    image = resize_to_fit(image, 28, 28)\n",
    "\n",
    "    # Add a third channel dimension to the image to make Keras happy\n",
    "    image = np.expand_dims(image, axis=2)\n",
    "\n",
    "    # Grab the name of the letter based on the folder it was in\n",
    "    label = image_file.split(os.path.sep)[-1].split('.')[-2].split('-')[1]\n",
    "\n",
    "    # Add the letter image and it's label to our training data\n",
    "    data_l_train.append(image)\n",
    "    labels_l_train.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTER_IMAGES_FOLDER = letters_test_dir\n",
    "\n",
    "# initialize the data and labels\n",
    "data_l_test = []\n",
    "labels_l_test = []\n",
    "\n",
    "# loop over the input images\n",
    "for image_file in sorted(paths.list_images(LETTER_IMAGES_FOLDER)):\n",
    "    # Load the image and convert it to grayscale\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize the letter so it fits in a 28x28 pixel box\n",
    "    image = resize_to_fit(image, 28, 28)\n",
    "\n",
    "    # Add a third channel dimension to the image to make Keras happy\n",
    "    image = np.expand_dims(image, axis=2)\n",
    "\n",
    "    # Grab the name of the letter based on the folder it was in\n",
    "    label = image_file.split(os.path.sep)[-1].split('.')[-2].split('-')[1]\n",
    "\n",
    "    # Add the letter image and it's label to our training data\n",
    "    data_l_test.append(image)\n",
    "    labels_l_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1340, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_l_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1] (this improves training)\n",
    "X_l_train = np.array(data_l_train, dtype=\"float\") / 255.0\n",
    "X_l_test = np.array(data_l_test, dtype=\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels (letters) into one-hot encodings that Keras can work with\n",
    "le = LabelEncoder().fit(np.array((labels_l_train + labels_l_test)))\n",
    "y_l_train = le.transform(np.array(labels_l_train))\n",
    "y_l_test = le.transform(np.array(labels_l_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 100\n",
    "batch_size_test = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l_train_t = (torch.from_numpy(X_l_train).float().transpose(1,3)).transpose(2,3)\n",
    "y_l_train_t = torch.from_numpy(y_l_train).long()\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(X_l_train_t, y_l_train_t)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=round(batch_size_train), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l_test_t = (torch.from_numpy(X_l_test).float().transpose(1,3)).transpose(2,3)\n",
    "y_l_test_t = torch.from_numpy(y_l_test).long()\n",
    "\n",
    "test_data = torch.utils.data.TensorDataset(X_l_test_t, y_l_test_t)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 120)\n",
    "        self.fc2 = nn.Linear(120, 19)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return F.log_softmax(x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, v=False):\n",
    "    net.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "        loss = F.nll_loss(output, target, reduction='mean')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            if v:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "            (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "        torch.save(net.state_dict(), 'model.pth')\n",
    "        torch.save(optimizer.state_dict(), 'optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = net(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "log_interval = 10\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 6.6338, Accuracy: 73/1340 (5%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.0913, Accuracy: 1017/1340 (75%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.7036, Accuracy: 1125/1340 (83%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.6005, Accuracy: 1197/1340 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.4569, Accuracy: 1220/1340 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.4172, Accuracy: 1233/1340 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.2449, Accuracy: 1247/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1579, Accuracy: 1249/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1776, Accuracy: 1260/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1557, Accuracy: 1259/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1878, Accuracy: 1248/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1171, Accuracy: 1256/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0616, Accuracy: 1259/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0562, Accuracy: 1271/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0543, Accuracy: 1264/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0364, Accuracy: 1266/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0295, Accuracy: 1273/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0432, Accuracy: 1262/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0191, Accuracy: 1271/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0178, Accuracy: 1263/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0381, Accuracy: 1257/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0242, Accuracy: 1259/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0397, Accuracy: 1264/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0192, Accuracy: 1262/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0394, Accuracy: 1259/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0147, Accuracy: 1268/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0050, Accuracy: 1264/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0180, Accuracy: 1267/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 3.9995, Accuracy: 1276/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0073, Accuracy: 1264/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 3.9972, Accuracy: 1275/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0061, Accuracy: 1266/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0009, Accuracy: 1269/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0094, Accuracy: 1273/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 3.9855, Accuracy: 1275/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0214, Accuracy: 1265/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0204, Accuracy: 1256/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0208, Accuracy: 1266/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 3.9995, Accuracy: 1270/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0074, Accuracy: 1266/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0359, Accuracy: 1272/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0782, Accuracy: 1248/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0148, Accuracy: 1268/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0480, Accuracy: 1253/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0151, Accuracy: 1265/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0139, Accuracy: 1260/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0101, Accuracy: 1270/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0024, Accuracy: 1275/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0068, Accuracy: 1268/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0041, Accuracy: 1272/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0072, Accuracy: 1261/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0050, Accuracy: 1270/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0160, Accuracy: 1263/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 3.9846, Accuracy: 1278/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 3.9904, Accuracy: 1271/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0004, Accuracy: 1278/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0355, Accuracy: 1274/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0180, Accuracy: 1273/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0195, Accuracy: 1259/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0255, Accuracy: 1273/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0544, Accuracy: 1260/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0357, Accuracy: 1265/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0389, Accuracy: 1265/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0344, Accuracy: 1264/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0368, Accuracy: 1271/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0351, Accuracy: 1270/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0052, Accuracy: 1274/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0397, Accuracy: 1274/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0485, Accuracy: 1272/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0321, Accuracy: 1268/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0221, Accuracy: 1267/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0557, Accuracy: 1270/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0598, Accuracy: 1267/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0450, Accuracy: 1259/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0100, Accuracy: 1273/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0143, Accuracy: 1266/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0468, Accuracy: 1273/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0311, Accuracy: 1276/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0441, Accuracy: 1270/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0250, Accuracy: 1266/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0523, Accuracy: 1264/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0719, Accuracy: 1256/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0457, Accuracy: 1258/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0535, Accuracy: 1265/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0640, Accuracy: 1264/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1037, Accuracy: 1256/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0618, Accuracy: 1268/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0558, Accuracy: 1272/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0632, Accuracy: 1264/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0498, Accuracy: 1274/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0626, Accuracy: 1275/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1353, Accuracy: 1253/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0616, Accuracy: 1273/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0558, Accuracy: 1261/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0390, Accuracy: 1253/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0925, Accuracy: 1264/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0782, Accuracy: 1271/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0465, Accuracy: 1273/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0376, Accuracy: 1276/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1373, Accuracy: 1262/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0912, Accuracy: 1273/1340 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTER_IMAGES_FOLDER = '../data/letters/test'\n",
    "\n",
    "\n",
    "# initialize the data and labels\n",
    "data_test = []\n",
    "labels_test = []\n",
    "\n",
    "# loop over the input images\n",
    "for d in os.listdir(LETTER_IMAGES_FOLDER):\n",
    "    aux = []\n",
    "    for image_file in sorted(paths.list_images(LETTER_IMAGES_FOLDER + '/' + d)):\n",
    "        # Load the image and convert it to grayscale\n",
    "        image = cv2.imread(image_file)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Resize the letter so it fits in a 28x28 pixel box\n",
    "        image = resize_to_fit(image, 28, 28)\n",
    "\n",
    "        # Add a third channel dimension to the image to make Keras happy\n",
    "        image = np.expand_dims(image, axis=2)\n",
    "        aux.append(image)\n",
    "        \n",
    "\n",
    "\n",
    "    data_test.append(aux)\n",
    "    labels_test.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 28, 28, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = []\n",
    "\n",
    "for i, e in enumerate(labels_test):\n",
    "    x = np.array(data_test[i], dtype=\"float\") / 255.0\n",
    "    x = (torch.from_numpy(x).float().transpose(1,3)).transpose(2,3)\n",
    "    out = net(x)\n",
    "    pred = out.data.max(1, keepdim=True)[1]\n",
    "    y = (''.join([e for e in le.inverse_transform(np.ravel(pred))]))\n",
    "    pred_test.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d3c8y d3c8y\n",
      "ny3dp ny5dp\n",
      "675p3 675p3\n",
      "g7ex5 g3ex3\n",
      "c7d5n 22d5n\n",
      "ydcpw xbcbx\n",
      "eg783 2g783\n",
      "3d2p4 3d7bd\n",
      "f2bge f2fge\n",
      "7gbge 7gnge\n",
      "37d5e 37d52\n",
      "264dn 664dn\n",
      "54g2e 5ng6e\n",
      "g7wxw g7wxw\n",
      "67gb3 62nb3\n",
      "6bxwg 6bxwg\n",
      "dpeyd dpbyd\n",
      "gm47f wm47f\n",
      "xbmcw wbncw\n",
      "532bm 5325m\n",
      "2n736 2n73f\n",
      "ngy3x dy3cx\n",
      "7cpwb 3cpwb\n",
      "dw6me dw6mn\n",
      "5b245 5n245\n",
      "4p2yg 4n2yg\n",
      "573ew 573d8\n",
      "m7gxf n7g4f\n",
      "8y63f 8y63f\n",
      "my3n6 ny3nn\n",
      "7xc2n 2xc2n\n",
      "658xe 658xe\n",
      "x24me x277e\n",
      "nmy2x nmy2x\n",
      "7bwpd nbwpn\n",
      "y87ny yw7ny\n",
      "c8we5 c6we6\n",
      "mgp48 bgb48\n",
      "wx3n8 wxcn8\n",
      "n7y3p 4743p\n",
      "d645x de45x\n",
      "gc83b gc83b\n",
      "gw468 gw468\n",
      "2y46p 25m6p\n",
      "7gebf 7g3nf\n",
      "76y5f 76y6f\n",
      "dy26n dn26n\n",
      "bgxcd bgxcd\n",
      "p2fen b2nen\n",
      "fbpwc fbp2c\n",
      "dmx8p dmx8p\n",
      "d4y82 d4n82\n",
      "p6mb8 p6mn8\n",
      "xyp5m yyg5g\n",
      "c7gb3 c7gb3\n",
      "gfx34 efx34\n",
      "ng2w5 ng2gw\n",
      "y5g87 y5g87\n",
      "6m4wx nn4wx\n",
      "w276m w7e6m\n",
      "42g6m 4egem\n",
      "4gbxf 4gb3f\n",
      "d2wpn dw3nn\n",
      "m8b57 nnn57\n",
      "6dnx7 6dmx7\n",
      "p8gyf p8wwf\n",
      "3p4mn 3p4nn\n",
      "38fg2 387g2\n",
      "x45n4 x44n4\n",
      "p3c7x 33f7m\n",
      "83mp5 43mn5\n",
      "4e8y7 7e2y7\n",
      "xemyg xemyg\n",
      "exycn exycn\n",
      "36p4m 8684m\n",
      "y48g3 y48c3\n",
      "fdxpn mdxpn\n",
      "dxfe8 dnmd8\n",
      "p8bgx p8ngx\n",
      "64b3p 64b3p\n",
      "bng2f bnc2f\n",
      "w43fn w4cnn\n",
      "c6745 c6745\n",
      "pc583 pcede\n",
      "pgy7e pgm2e\n",
      "3ebpw 3ebpw\n",
      "f728n f228n\n",
      "7gm83 7gmf3\n",
      "mgw3n mgw3n\n",
      "8g34m 8n34n\n",
      "yfwp4 77wp4\n",
      "fg6xb fc6xb\n",
      "myg68 mye68\n",
      "m2dn6 728n8\n",
      "cpe63 cpe63\n",
      "25egp 25egp\n",
      "mg824 yy824\n",
      "e7bmn e3ndn\n",
      "xb7cw xyyyw\n",
      "6pwcf 6pwcn\n",
      "bpwd7 bpwd7\n",
      "6fg82 6fg8c\n",
      "m452d m457d\n",
      "5gdwb mgdwb\n",
      "3mxdn 3mxdn\n",
      "cwgyx cwgyx\n",
      "5g8d3 5gcd3\n",
      "e8x47 28x47\n",
      "ndp7b ndg2b\n",
      "d8mcn d8xcn\n",
      "f35xp f35xp\n",
      "ecd8w ecd4w\n",
      "64m82 64m82\n",
      "p2bgx p2x7x\n",
      "c8gnd g8gnd\n",
      "x4dp5 x4gg5\n",
      "pewyd ppwyd\n",
      "8wb67 8db67\n",
      "pwg24 p8c24\n",
      "nmp4e nnp4e\n",
      "gwb53 gwn53\n",
      "gc27f gc277\n",
      "846fe 85622\n",
      "c2bn8 cnmnn\n",
      "xc68n xc68n\n",
      "8xwp7 bdbb3\n",
      "fp7w5 mp7wp\n",
      "6dnm3 6gnm3\n",
      "2wnd7 3wnd3\n",
      "dc2m8 fc2ff\n",
      "6e2by 6e2dg\n",
      "6g2b5 662bw\n",
      "pg26m pg2pm\n",
      "e6b7y e6b7y\n",
      "pe4xn pe4xn\n",
      "mng28 mmg2m\n",
      "npxb7 npxb7\n",
      "2w4y7 2w4y7\n",
      "f3ypb 3ye2e\n",
      "n4b5m n4b4m\n",
      "gfny5 dbny3\n",
      "n7ebx n7ebx\n",
      "w4nfx w4nfx\n",
      "fnpw3 fxpw3\n",
      "fexdm 5expp\n",
      "mxy8w mxyxw\n",
      "w2e87 w2e87\n",
      "py7fb pyefb\n",
      "g8fe3 gdng3\n",
      "efgx5 efgx5\n",
      "wnym3 wmpmp\n",
      "fg8n4 fg8n4\n",
      "3enw7 3eny7\n",
      "8bf35 8b735\n",
      "bywe2 xxw44\n",
      "7fgey f7cey\n",
      "yc2bd wc2bd\n",
      "68nmc 6wnyc\n",
      "d2me7 dnne7\n",
      "7gbnx 7nnnx\n",
      "7gxb6 7dxbd\n",
      "23f6w 24f6w\n",
      "4xcme nxcmn\n",
      "fdp84 bdg84\n",
      "7p85c 7p852\n",
      "3ygde 3ygde\n",
      "dpxn7 gpxng\n",
      "ygbwe ygfwe\n",
      "4gycb 4gycb\n",
      "87nyw 87nym\n",
      "pf6y4 w6ny4\n",
      "5byd7 5bnd7\n",
      "xdcn4 xdcn4\n",
      "p8mbn pwmbn\n",
      "57wdp 57wdp\n",
      "cwm4y cwmny\n",
      "cd4eg cd4eg\n",
      "cem23 een23\n",
      "58b5m 58b5m\n",
      "8npe3 8npe3\n",
      "gd4mf gd4mf\n",
      "57n8c 5mf7c\n",
      "6mygb 6mygb\n",
      "p52fn p57fn\n",
      "nfbg5 nfbg8\n",
      "63pxe 63pxe\n",
      "n5cg7 n5cm7\n",
      "w27bn w52fn\n",
      "4y3ex 4ycex\n",
      "ygp7c yge7c\n",
      "36nby 56m6y\n",
      "e46yw e46yw\n",
      "gyc3m gnc3n\n",
      "pxne8 pxne8\n",
      "x8e6n x8e8n\n",
      "pcm7f pcm7f\n",
      "m2c85 n2c85\n",
      "wxfey xxney\n",
      "4ygwd nn6w6\n",
      "4bcgp nbcgb\n",
      "4cm2p 4cn7b\n",
      "n2gx7 n2gmg\n",
      "m3wby m3wfw\n",
      "y4c58 y3c58\n",
      "p287n pp87n\n",
      "gy8xb gy8xb\n",
      "4nfx3 nnfx3\n",
      "x3deb x3deb\n",
      "gw5n3 gm6nn\n",
      "f6py8 f6ww8\n",
      "8b2m4 8bbm4\n",
      "gxm8p e6m6p\n",
      "f85y3 f85y3\n",
      "b642p b6f2p\n",
      "y2x8p y7x8p\n",
      "cpn8g f8f8g\n",
      "y326y y32yy\n",
      "c2dmc cndmc\n",
      "3ym7f 3ym7f\n",
      "mefbd befbd\n",
      "w6yne w6yne\n",
      "f5cn2 f5cm2\n",
      "gbxwc gfxcc\n",
      "6753n f753f\n",
      "mfcb5 nfcb5\n",
      "3nmpw 3nnpw\n",
      "3c8nf bc8nf\n",
      "ewmx8 ewnx8\n",
      "g86fm d666m\n",
      "wnf85 gnf85\n",
      "g2bnw g2fnw\n",
      "byc82 byc82\n",
      "xng3y xnd3y\n",
      "e8mx7 gpnxn\n",
      "6g3p5 deep5\n",
      "5x5nc 5x5nx\n",
      "2xbxm 2x7bm\n",
      "pwn5e pwn5e\n",
      "b5m7f b5nmm\n",
      "3fd8g nfd8g\n",
      "7dpc2 7dgc2\n",
      "d2ybw d2ycw\n",
      "x3bwf x3fwf\n",
      "n3xfg n3xfg\n",
      "2emf4 2enf4\n",
      "fp762 fp762\n",
      "dyfgn byfgn\n",
      "4new5 4m2w5\n",
      "8gy54 8w754\n",
      "p5nce p5nce\n",
      "m4fd8 m4fd8\n",
      "d78y5 d22y5\n",
      "n7dc4 mn5c4\n",
      "wwm46 wwmn6\n",
      "my24e my84e\n",
      "467d5 467d5\n",
      "dd8me ddcne\n",
      "nb8we nbp3e\n",
      "pmd3w pmd3w\n",
      "fcey3 fcey3\n",
      "weyp7 w2yp7\n",
      "n3bw6 n3bm6\n",
      "n265y n265y\n",
      "bp2dy bp2d4\n",
      "6wxf8 nxxf8\n",
      "x467g x4f7g\n",
      "n3f6x n3m6x\n",
      "geyw4 gegw4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for e, f in zip(pred_test, labels_test):\n",
    "    print(e, f)\n",
    "    if e == f:\n",
    "        correct += 1\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23880597014925373"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/len(pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
