{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import cv2\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "os.sys.path.append('../src')\n",
    "from helpers import resize_to_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.abspath(os.path.relpath('../data'))\n",
    "image_dir = os.path.abspath(os.path.relpath('../doc/images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPTCHA_IMAGES_FOLDER = \"../data/samples\"\n",
    "\n",
    "# initialize the data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# loop over the input images\n",
    "for image_file in paths.list_images(CAPTCHA_IMAGES_FOLDER):\n",
    "    # Load the image and convert it to grayscale\n",
    "\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Grab the labels\n",
    "    label = image_file.split(os.path.sep)[-1].split('.')[-2]\n",
    "\n",
    "    # Add the image and it's label to our training data\n",
    "    data.append(image)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(data, labels, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images(data, label):\n",
    "    # Otsu threashold\n",
    "    data_pre = []\n",
    "    for e in data:\n",
    "        ret, th = cv2.threshold(e, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        dilation = cv2.dilate(th, kernel, iterations=1)\n",
    "        erosion = cv2.erode(dilation, kernel, iterations=1)\n",
    "        data_pre.append(erosion)\n",
    "    \n",
    "    # K-means\n",
    "    data_pts = []\n",
    "    for e in data_pre:\n",
    "        data_pts.append(np.where(e == 0))\n",
    "    data_pts = np.array(data_pts)\n",
    "    \n",
    "    X = []\n",
    "    thres = 3\n",
    "    for e in data_pts:\n",
    "        x = (np.vstack((e[1],np.flip(e[0])))).T\n",
    "        l = []\n",
    "        # Discard columns with less than thres points\n",
    "        for i in range(200):\n",
    "            if len(x[x[:,0] == i]) > thres:\n",
    "                for f in x[x[:,0] == i]:\n",
    "                    l.append(f)\n",
    "        x = np.array(l)\n",
    "        X.append(x)\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # Projection in x-axis\n",
    "    X_proj = [x[:,0].reshape(-1,1) for x in X]\n",
    "    \n",
    "    # Find clusters in projected data\n",
    "    y_kmeans_proj = []\n",
    "    centers_kmeans_proj = []\n",
    "    for i, x in enumerate(X_proj):\n",
    "        kmeans = KMeans(n_clusters=5)#, init=np.array([(i*200/6.0, 25) for i in range(1,6)]))\n",
    "        kmeans.fit(x)\n",
    "        centers_kmeans_proj.append(kmeans.cluster_centers_)\n",
    "        y_kmeans_proj.append(kmeans.predict(x))\n",
    "\n",
    "    centers = [np.sort(e, axis=0) for e in centers_kmeans_proj]\n",
    "    data_chars = []\n",
    "    for i, e in enumerate(data_pre):\n",
    "        chars = []\n",
    "        for j in range(5):\n",
    "            chars.append(e[:,int(centers[i][j]-21):int(centers[i][j]+21)])\n",
    "        data_chars.append(chars)\n",
    "        \n",
    "    return data_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_train_dir = '../data/letters/train'\n",
    "\n",
    "data_chars = create_images(X_train, y_train)\n",
    "\n",
    "if not(os.path.isdir(''.join((letters_train_dir)))):\n",
    "    os.mkdir(''.join((letters_train_dir)))\n",
    "\n",
    "for i,e in enumerate(data_chars):\n",
    "    for j in range(5):\n",
    "        if not(os.path.isdir(''.join((letters_train_dir,'/',y_train[i],'/')))):\n",
    "            os.mkdir(''.join((letters_train_dir,'/',y_train[i],'/')))\n",
    "        cv2.imwrite(''.join((letters_train_dir,'/',y_train[i],'/',str(j),'-',y_train[i][j],'.png')),e[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_test_dir = '../data/letters/test'\n",
    "\n",
    "data_chars_test = create_images(X_test, y_test)\n",
    "\n",
    "if not(os.path.isdir(''.join((letters_test_dir)))):\n",
    "    os.mkdir(''.join((letters_test_dir)))\n",
    "\n",
    "for i,e in enumerate(data_chars_test):\n",
    "    for j in range(5):\n",
    "        if not(os.path.isdir(''.join((letters_test_dir,'/',y_test[i],'/')))):\n",
    "            os.mkdir(''.join((letters_test_dir,'/',y_test[i],'/')))\n",
    "        cv2.imwrite(''.join((letters_test_dir,'/',y_test[i],'/',str(j),'-',y_test[i][j],'.png')),e[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTER_IMAGES_FOLDER = letters_train_dir\n",
    "\n",
    "# initialize the data and labels\n",
    "data_l_train = []\n",
    "labels_l_train = []\n",
    "\n",
    "# loop over the input images\n",
    "for image_file in paths.list_images(LETTER_IMAGES_FOLDER):\n",
    "    # Load the image and convert it to grayscale\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize the letter so it fits in a 28x28 pixel box\n",
    "    image = resize_to_fit(image, 28, 28)\n",
    "\n",
    "    # Add a third channel dimension to the image to make Keras happy\n",
    "    image = np.expand_dims(image, axis=2)\n",
    "\n",
    "    # Grab the name of the letter based on the folder it was in\n",
    "    label = image_file.split(os.path.sep)[-1].split('.')[-2].split('-')[1]\n",
    "\n",
    "    # Add the letter image and it's label to our training data\n",
    "    data_l_train.append(image)\n",
    "    labels_l_train.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTER_IMAGES_FOLDER = letters_test_dir\n",
    "\n",
    "# initialize the data and labels\n",
    "data_l_test = []\n",
    "labels_l_test = []\n",
    "\n",
    "# loop over the input images\n",
    "for image_file in sorted(paths.list_images(LETTER_IMAGES_FOLDER)):\n",
    "    # Load the image and convert it to grayscale\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize the letter so it fits in a 28x28 pixel box\n",
    "    image = resize_to_fit(image, 28, 28)\n",
    "\n",
    "    # Add a third channel dimension to the image to make Keras happy\n",
    "    image = np.expand_dims(image, axis=2)\n",
    "\n",
    "    # Grab the name of the letter based on the folder it was in\n",
    "    label = image_file.split(os.path.sep)[-1].split('.')[-2].split('-')[1]\n",
    "\n",
    "    # Add the letter image and it's label to our training data\n",
    "    data_l_test.append(image)\n",
    "    labels_l_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1340, 28, 28, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_l_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1] (this improves training)\n",
    "X_l_train = np.array(data_l_train, dtype=\"float\") / 255.0\n",
    "X_l_test = np.array(data_l_test, dtype=\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels (letters) into one-hot encodings that Keras can work with\n",
    "le = LabelEncoder().fit(np.array((labels_l_train + labels_l_test)))\n",
    "y_l_train = le.transform(np.array(labels_l_train))\n",
    "y_l_test = le.transform(np.array(labels_l_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 100\n",
    "batch_size_test = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l_train_t = (torch.from_numpy(X_l_train).float().transpose(1,3)).transpose(2,3)\n",
    "y_l_train_t = torch.from_numpy(y_l_train).long()\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(X_l_train_t, y_l_train_t)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=round(batch_size_train), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l_test_t = (torch.from_numpy(X_l_test).float().transpose(1,3)).transpose(2,3)\n",
    "y_l_test_t = torch.from_numpy(y_l_test).long()\n",
    "\n",
    "test_data = torch.utils.data.TensorDataset(X_l_test_t, y_l_test_t)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 120)\n",
    "        self.fc2 = nn.Linear(120, 32)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return F.log_softmax(x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, v=False):\n",
    "    net.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "        loss = F.nll_loss(output, target, reduction='mean')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            if v:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "            (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "        torch.save(net.state_dict(), 'model.pth')\n",
    "        torch.save(optimizer.state_dict(), 'optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = net(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "log_interval = 10\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 6.6332, Accuracy: 48/1340 (3%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.0130, Accuracy: 958/1340 (71%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.6639, Accuracy: 1082/1340 (80%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.5171, Accuracy: 1147/1340 (85%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.4394, Accuracy: 1172/1340 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.3442, Accuracy: 1196/1340 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.4097, Accuracy: 1199/1340 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.2513, Accuracy: 1220/1340 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.2828, Accuracy: 1197/1340 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.2078, Accuracy: 1229/1340 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.2524, Accuracy: 1214/1340 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.2047, Accuracy: 1237/1340 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1360, Accuracy: 1231/1340 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1560, Accuracy: 1241/1340 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1822, Accuracy: 1234/1340 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1186, Accuracy: 1248/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1284, Accuracy: 1230/1340 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0979, Accuracy: 1248/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1307, Accuracy: 1246/1340 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0723, Accuracy: 1255/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0701, Accuracy: 1250/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0742, Accuracy: 1250/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0941, Accuracy: 1249/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0719, Accuracy: 1251/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0531, Accuracy: 1243/1340 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0780, Accuracy: 1244/1340 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0490, Accuracy: 1251/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0733, Accuracy: 1245/1340 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0420, Accuracy: 1250/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0553, Accuracy: 1252/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0463, Accuracy: 1258/1340 (93%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTER_IMAGES_FOLDER = '../data/letters/test'\n",
    "\n",
    "\n",
    "# initialize the data and labels\n",
    "data_test = []\n",
    "labels_test = []\n",
    "\n",
    "# loop over the input images\n",
    "for d in os.listdir(LETTER_IMAGES_FOLDER):\n",
    "    aux = []\n",
    "    for image_file in sorted(paths.list_images(LETTER_IMAGES_FOLDER + '/' + d)):\n",
    "        # Load the image and convert it to grayscale\n",
    "        image = cv2.imread(image_file)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Resize the letter so it fits in a 28x28 pixel box\n",
    "        image = resize_to_fit(image, 28, 28)\n",
    "\n",
    "        # Add a third channel dimension to the image to make Keras happy\n",
    "        image = np.expand_dims(image, axis=2)\n",
    "        aux.append(image)\n",
    "        \n",
    "\n",
    "\n",
    "    data_test.append(aux)\n",
    "    labels_test.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 28, 28, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = []\n",
    "\n",
    "for i, e in enumerate(labels_test):\n",
    "    x = np.array(data_test[i], dtype=\"float\") / 255.0\n",
    "    x = (torch.from_numpy(x).float().transpose(1,3)).transpose(2,3)\n",
    "    out = net(x)\n",
    "    pred = out.data.max(1, keepdim=True)[1]\n",
    "    y = (''.join([e for e in le.inverse_transform(np.ravel(pred))]))\n",
    "    pred_test.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for e, f in zip(pred_test, labels_test):\n",
    "    if e == f:\n",
    "        correct += 1\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.332089552238806"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/len(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
