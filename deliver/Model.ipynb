{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import cv2\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "os.sys.path.append('../src')\n",
    "from helpers import resize_to_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.abspath(os.path.relpath('../data'))\n",
    "image_dir = os.path.abspath(os.path.relpath('../doc/images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPTCHA_IMAGES_FOLDER = \"../data/samples\"\n",
    "\n",
    "# initialize the data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# loop over the input images\n",
    "for image_file in paths.list_images(CAPTCHA_IMAGES_FOLDER):\n",
    "    # Load the image and convert it to grayscale\n",
    "\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Grab the labels\n",
    "    label = image_file.split(os.path.sep)[-1].split('.')[-2]\n",
    "\n",
    "    # Add the image and it's label to our training data\n",
    "    data.append(image)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(data, labels, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images(data, label):\n",
    "    # Otsu threashold\n",
    "    data_pre = []\n",
    "    for e in data:\n",
    "        ret, th = cv2.threshold(e, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        dilation = cv2.dilate(th, kernel, iterations=1)\n",
    "        erosion = cv2.erode(dilation, kernel, iterations=1)\n",
    "        data_pre.append(erosion)\n",
    "    \n",
    "    # K-means\n",
    "    data_pts = []\n",
    "    for e in data_pre:\n",
    "        data_pts.append(np.where(e == 0))\n",
    "    data_pts = np.array(data_pts)\n",
    "    \n",
    "    X = []\n",
    "    thres = 3\n",
    "    for e in data_pts:\n",
    "        x = (np.vstack((e[1],np.flip(e[0])))).T\n",
    "        l = []\n",
    "        # Discard columns with less than thres points\n",
    "        for i in range(200):\n",
    "            if len(x[x[:,0] == i]) > thres:\n",
    "                for f in x[x[:,0] == i]:\n",
    "                    l.append(f)\n",
    "        x = np.array(l)\n",
    "        X.append(x)\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # Projection in x-axis\n",
    "    X_proj = [x[:,0].reshape(-1,1) for x in X]\n",
    "    \n",
    "    # Find clusters in projected data\n",
    "    y_kmeans_proj = []\n",
    "    centers_kmeans_proj = []\n",
    "    for i, x in enumerate(X_proj):\n",
    "        kmeans = KMeans(n_clusters=5)#, init=np.array([(i*200/6.0, 25) for i in range(1,6)]))\n",
    "        kmeans.fit(x)\n",
    "        centers_kmeans_proj.append(kmeans.cluster_centers_)\n",
    "        y_kmeans_proj.append(kmeans.predict(x))\n",
    "\n",
    "    centers = [np.sort(e, axis=0) for e in centers_kmeans_proj]\n",
    "    data_chars = []\n",
    "    for i, e in enumerate(data_pre):\n",
    "        chars = []\n",
    "        for j in range(5):\n",
    "            chars.append(e[:,int(centers[i][j]-21):int(centers[i][j]+21)])\n",
    "        data_chars.append(chars)\n",
    "        \n",
    "    return data_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_train_dir = '../data/letters/train'\n",
    "\n",
    "data_chars = create_images(X_train, y_train)\n",
    "\n",
    "if not(os.path.isdir(''.join((letters_train_dir)))):\n",
    "    os.mkdir(''.join((letters_train_dir)))\n",
    "\n",
    "for i,e in enumerate(data_chars):\n",
    "    for j in range(5):\n",
    "        if not(os.path.isdir(''.join((letters_train_dir,'/',y_train[i],'/')))):\n",
    "            os.mkdir(''.join((letters_train_dir,'/',y_train[i],'/')))\n",
    "        cv2.imwrite(''.join((letters_train_dir,'/',y_train[i],'/',str(j),'-',y_train[i][j],'.png')),e[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_test_dir = '../data/letters/test'\n",
    "\n",
    "data_chars_test = create_images(X_test, y_test)\n",
    "\n",
    "if not(os.path.isdir(''.join((letters_test_dir)))):\n",
    "    os.mkdir(''.join((letters_test_dir)))\n",
    "\n",
    "for i,e in enumerate(data_chars_test):\n",
    "    for j in range(5):\n",
    "        if not(os.path.isdir(''.join((letters_test_dir,'/',y_test[i],'/')))):\n",
    "            os.mkdir(''.join((letters_test_dir,'/',y_test[i],'/')))\n",
    "        cv2.imwrite(''.join((letters_test_dir,'/',y_test[i],'/',str(j),'-',y_test[i][j],'.png')),e[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTER_IMAGES_FOLDER = letters_train_dir\n",
    "\n",
    "# initialize the data and labels\n",
    "data_l_train = []\n",
    "labels_l_train = []\n",
    "\n",
    "# loop over the input images\n",
    "for image_file in paths.list_images(LETTER_IMAGES_FOLDER):\n",
    "    # Load the image and convert it to grayscale\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize the letter so it fits in a 28x28 pixel box\n",
    "    image = resize_to_fit(image, 32, 32)\n",
    "\n",
    "    # Add a third channel dimension to the image to make Keras happy\n",
    "    image = np.expand_dims(image, axis=2)\n",
    "\n",
    "    # Grab the name of the letter based on the folder it was in\n",
    "    label = image_file.split(os.path.sep)[-1].split('.')[-2].split('-')[1]\n",
    "\n",
    "    # Add the letter image and it's label to our training data\n",
    "    data_l_train.append(image)\n",
    "    labels_l_train.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTER_IMAGES_FOLDER = letters_test_dir\n",
    "\n",
    "# initialize the data and labels\n",
    "data_l_test = []\n",
    "labels_l_test = []\n",
    "\n",
    "# loop over the input images\n",
    "for image_file in sorted(paths.list_images(LETTER_IMAGES_FOLDER)):\n",
    "    # Load the image and convert it to grayscale\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize the letter so it fits in a 28x28 pixel box\n",
    "    image = resize_to_fit(image, 32, 32)\n",
    "\n",
    "    # Add a third channel dimension to the image to make Keras happy\n",
    "    image = np.expand_dims(image, axis=2)\n",
    "\n",
    "    # Grab the name of the letter based on the folder it was in\n",
    "    label = image_file.split(os.path.sep)[-1].split('.')[-2].split('-')[1]\n",
    "\n",
    "    # Add the letter image and it's label to our training data\n",
    "    data_l_test.append(image)\n",
    "    labels_l_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1340, 32, 32, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_l_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1] (this improves training)\n",
    "X_l_train = np.array(data_l_train, dtype=\"float\") / 255.0\n",
    "X_l_test = np.array(data_l_test, dtype=\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels (letters) into one-hot encodings that Keras can work with\n",
    "le = LabelEncoder().fit(np.array((labels_l_train + labels_l_test)))\n",
    "y_l_train = le.transform(np.array(labels_l_train))\n",
    "y_l_test = le.transform(np.array(labels_l_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 100\n",
    "batch_size_test = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l_train_t = (torch.from_numpy(X_l_train).float().transpose(1,3)).transpose(2,3)\n",
    "y_l_train_t = torch.from_numpy(y_l_train).long()\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(X_l_train_t, y_l_train_t)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=round(batch_size_train), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l_test_t = (torch.from_numpy(X_l_test).float().transpose(1,3)).transpose(2,3)\n",
    "y_l_test_t = torch.from_numpy(y_l_test).long()\n",
    "\n",
    "test_data = torch.utils.data.TensorDataset(X_l_test_t, y_l_test_t)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(400, 340)\n",
    "        self.fc2 = nn.Linear(340, 19)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 400)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return F.log_softmax(x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, v=False):\n",
    "    net.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "        loss = F.nll_loss(output, target, reduction='mean')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            if v:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "            (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "        torch.save(net.state_dict(), 'model.pth')\n",
    "        torch.save(optimizer.state_dict(), 'optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = net(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "log_interval = 10\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 6.6346, Accuracy: 77/1340 (5%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.0590, Accuracy: 1001/1340 (74%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.5781, Accuracy: 1131/1340 (84%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.6224, Accuracy: 1170/1340 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.4489, Accuracy: 1193/1340 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.4378, Accuracy: 1213/1340 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.3169, Accuracy: 1224/1340 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.2878, Accuracy: 1235/1340 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.2559, Accuracy: 1239/1340 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.2216, Accuracy: 1252/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.2756, Accuracy: 1227/1340 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.2199, Accuracy: 1248/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1892, Accuracy: 1246/1340 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1845, Accuracy: 1251/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1460, Accuracy: 1250/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1306, Accuracy: 1244/1340 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1296, Accuracy: 1257/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1229, Accuracy: 1255/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1202, Accuracy: 1253/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1271, Accuracy: 1245/1340 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1057, Accuracy: 1250/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0820, Accuracy: 1255/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1039, Accuracy: 1251/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1064, Accuracy: 1255/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0627, Accuracy: 1263/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0765, Accuracy: 1257/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0815, Accuracy: 1253/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0537, Accuracy: 1261/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0749, Accuracy: 1251/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0445, Accuracy: 1267/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0850, Accuracy: 1239/1340 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0569, Accuracy: 1255/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0501, Accuracy: 1261/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0649, Accuracy: 1252/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0504, Accuracy: 1259/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0545, Accuracy: 1255/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0376, Accuracy: 1257/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0449, Accuracy: 1261/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0435, Accuracy: 1257/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0688, Accuracy: 1264/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0544, Accuracy: 1261/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0707, Accuracy: 1260/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0328, Accuracy: 1261/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0315, Accuracy: 1262/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0380, Accuracy: 1262/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0566, Accuracy: 1257/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0555, Accuracy: 1247/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0405, Accuracy: 1265/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0214, Accuracy: 1266/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0382, Accuracy: 1262/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0429, Accuracy: 1260/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0334, Accuracy: 1260/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0651, Accuracy: 1249/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0374, Accuracy: 1253/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0688, Accuracy: 1256/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0342, Accuracy: 1257/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0396, Accuracy: 1258/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0282, Accuracy: 1261/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0277, Accuracy: 1265/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0662, Accuracy: 1260/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0374, Accuracy: 1263/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0263, Accuracy: 1265/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0428, Accuracy: 1265/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0244, Accuracy: 1266/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0345, Accuracy: 1267/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0356, Accuracy: 1267/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0359, Accuracy: 1260/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0445, Accuracy: 1259/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0568, Accuracy: 1263/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0513, Accuracy: 1258/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0335, Accuracy: 1265/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0426, Accuracy: 1263/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0329, Accuracy: 1273/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0254, Accuracy: 1268/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0313, Accuracy: 1273/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0410, Accuracy: 1268/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0402, Accuracy: 1260/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0357, Accuracy: 1260/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0317, Accuracy: 1268/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0474, Accuracy: 1258/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0686, Accuracy: 1259/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0729, Accuracy: 1248/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0290, Accuracy: 1262/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1189, Accuracy: 1237/1340 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.2449, Accuracy: 1205/1340 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.1693, Accuracy: 1229/1340 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0936, Accuracy: 1249/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0797, Accuracy: 1253/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0727, Accuracy: 1259/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0615, Accuracy: 1252/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0804, Accuracy: 1265/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0818, Accuracy: 1266/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0212, Accuracy: 1277/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0741, Accuracy: 1252/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0359, Accuracy: 1262/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0525, Accuracy: 1270/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0431, Accuracy: 1266/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0281, Accuracy: 1260/1340 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0423, Accuracy: 1275/1340 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0398, Accuracy: 1257/1340 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.0516, Accuracy: 1258/1340 (93%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTER_IMAGES_FOLDER = '../data/letters/test'\n",
    "\n",
    "\n",
    "# initialize the data and labels\n",
    "data_test = []\n",
    "labels_test = []\n",
    "\n",
    "# loop over the input images\n",
    "for d in os.listdir(LETTER_IMAGES_FOLDER):\n",
    "    aux = []\n",
    "    for image_file in sorted(paths.list_images(LETTER_IMAGES_FOLDER + '/' + d)):\n",
    "        # Load the image and convert it to grayscale\n",
    "        image = cv2.imread(image_file)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Resize the letter so it fits in a 28x28 pixel box\n",
    "        image = resize_to_fit(image, 32, 32)\n",
    "\n",
    "        # Add a third channel dimension to the image to make Keras happy\n",
    "        image = np.expand_dims(image, axis=2)\n",
    "        aux.append(image)\n",
    "        \n",
    "\n",
    "\n",
    "    data_test.append(aux)\n",
    "    labels_test.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32, 32, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = []\n",
    "\n",
    "for i, e in enumerate(labels_test):\n",
    "    x = np.array(data_test[i], dtype=\"float\") / 255.0\n",
    "    x = (torch.from_numpy(x).float().transpose(1,3)).transpose(2,3)\n",
    "    out = net(x)\n",
    "    pred = out.data.max(1, keepdim=True)[1]\n",
    "    y = (''.join([e for e in le.inverse_transform(np.ravel(pred))]))\n",
    "    pred_test.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d3c6y d3c8y\n",
      "ny5fp ny5dp\n",
      "675p3 675p3\n",
      "gdpx3 g3ex3\n",
      "72d5n 22d5n\n",
      "7bebf xbcbx\n",
      "2p783 2g783\n",
      "8dwxf 3d7bd\n",
      "c2fge f2fge\n",
      "7d6ge 7gnge\n",
      "37g52 37d52\n",
      "564dm 664dn\n",
      "5ngpe 5ng6e\n",
      "d7yxw g7wxw\n",
      "62nb3 62nb3\n",
      "6bxwg 6bxwg\n",
      "2pbyd dpbyd\n",
      "ym67f wm47f\n",
      "xbncw wbncw\n",
      "532by 5325m\n",
      "2n73f 2n73f\n",
      "8fy3x dy3cx\n",
      "3cpwb 3cpwb\n",
      "dy6mn dw6mn\n",
      "bn24y 5n245\n",
      "4b2yg 4n2yg\n",
      "573e8 573d8\n",
      "n7g4f n7g4f\n",
      "8y63f 8y63f\n",
      "my3f6 ny3nn\n",
      "25xpn 2xc2n\n",
      "658xe 658xe\n",
      "x27ne x277e\n",
      "n3y2x nmy2x\n",
      "mbwp4 nbwpn\n",
      "5w7n4 yw7ny\n",
      "c6web c6we6\n",
      "fgy48 bgb48\n",
      "w6cn8 wxcn8\n",
      "87d3p 4743p\n",
      "de45x de45x\n",
      "gc83b gc83b\n",
      "gw468 gw468\n",
      "2bm6p 25m6p\n",
      "5xgnf 7g3nf\n",
      "7by8f 76y6f\n",
      "gm25n dn26n\n",
      "bgxcd bgxcd\n",
      "b74ep b2nen\n",
      "fbm2c fbp2c\n",
      "dmx8p dmx8p\n",
      "d4b82 d4n82\n",
      "p6yn8 p6mn8\n",
      "fwd5m yyg5g\n",
      "c7gb3 c7gb3\n",
      "efx34 efx34\n",
      "mg2c7 ng2gw\n",
      "y3g87 y5g87\n",
      "m84cx nn4wx\n",
      "pfg6n w7e6m\n",
      "4pgcm 4egem\n",
      "4gb3f 4gb3f\n",
      "d8w3n dw3nn\n",
      "ngm57 nnn57\n",
      "6dmx7 6dmx7\n",
      "p87gf p8wwf\n",
      "3p4n7 3p4nn\n",
      "387g2 387g2\n",
      "x8dn4 x44n4\n",
      "36f7m 33f7m\n",
      "43mn5 43mn5\n",
      "5e2yf 7e2y7\n",
      "x8myg xemyg\n",
      "exycn exycn\n",
      "8654p 8684m\n",
      "y48c3 y48c3\n",
      "7dxpn mdxpn\n",
      "dnme8 dnmd8\n",
      "p86gf p8ngx\n",
      "64b3p 64b3p\n",
      "bnc26 bnc2f\n",
      "w4cn7 w4cnn\n",
      "c6745 c6745\n",
      "pcedy pcede\n",
      "pgm7e pgm2e\n",
      "4mbpw 3ebpw\n",
      "f228e f228n\n",
      "7gmf3 7gmf3\n",
      "fgw3p mgw3n\n",
      "8n3fp 8n34n\n",
      "2fypd 77wp4\n",
      "fc6xb fc6xb\n",
      "myb68 mye68\n",
      "72bn6 728n8\n",
      "cpe63 cpe63\n",
      "25emp 25egp\n",
      "gc824 yy824\n",
      "e3x2g e3ndn\n",
      "xy6e8 xyyyw\n",
      "8pwcn 6pwcn\n",
      "bpwd7 bpwd7\n",
      "6fg8c 6fg8c\n",
      "m45gd m457d\n",
      "mgfxb mgdwb\n",
      "3mxde 3mxdn\n",
      "cwgyx cwgyx\n",
      "5gcd3 5gcd3\n",
      "28x47 28x47\n",
      "w872b ndg2b\n",
      "d8xcn d8xcn\n",
      "f35xe f35xp\n",
      "pcd4w ecd4w\n",
      "64m82 64m82\n",
      "m2y7w p2x7x\n",
      "y8g6d g8gnd\n",
      "x4ge5 x4gg5\n",
      "epwyd ppwyd\n",
      "8gb67 8db67\n",
      "p8c24 p8c24\n",
      "mn64e nnp4e\n",
      "gwm53 gwn53\n",
      "gc254 gc277\n",
      "856n2 85622\n",
      "cgmnw cnmnn\n",
      "xc68n xc68n\n",
      "fgcb3 bdbb3\n",
      "megyp mp7wp\n",
      "6gym3 6gnm3\n",
      "5wmd3 3wnd3\n",
      "mc2dw fc2ff\n",
      "6e24g 6e2dg\n",
      "562mw 662bw\n",
      "6g3by pg2pm\n",
      "e6b7y e6b7y\n",
      "pe4xn pe4xn\n",
      "6yg2n mmg2m\n",
      "4pxb7 npxb7\n",
      "pw4y7 2w4y7\n",
      "n3ype 3ye2e\n",
      "n4bde n4b4m\n",
      "dbny3 dbny3\n",
      "n7ebx n7ebx\n",
      "w4nfx w4nfx\n",
      "fxpw3 fxpw3\n",
      "5exbp 5expp\n",
      "mxypw mxyxw\n",
      "w2e87 w2e87\n",
      "pyefb pyefb\n",
      "gcfe3 gdng3\n",
      "efgx5 efgx5\n",
      "weg48 wmpmp\n",
      "fc8n3 fg8n4\n",
      "3eny7 3eny7\n",
      "8b7g5 8b735\n",
      "pxwe8 xxw44\n",
      "4fcey f7cey\n",
      "wc2bd wc2bd\n",
      "fdnxc 6wnyc\n",
      "dmne7 dnne7\n",
      "7mfex 7nnnx\n",
      "7dfbn 7dxbd\n",
      "24f6w 24f6w\n",
      "n8cme nxcmn\n",
      "bcp84 bdg84\n",
      "7p8f2 7p852\n",
      "3ygde 3ygde\n",
      "cpx4g gpxng\n",
      "yg8we ygfwe\n",
      "4gycb 4gycb\n",
      "87nym 87nym\n",
      "mfbg4 w6ny4\n",
      "5bnd7 5bnd7\n",
      "xdcn4 xdcn4\n",
      "p4mbe pwmbn\n",
      "57wdp 57wdp\n",
      "cwmny cwmny\n",
      "cd4eg cd4eg\n",
      "cen23 een23\n",
      "d8b6m 58b5m\n",
      "8npe3 8npe3\n",
      "gd7mf gd4mf\n",
      "5p7fc 5mf7c\n",
      "6mygb 6mygb\n",
      "p5xfn p57fn\n",
      "nfbg8 nfbg8\n",
      "43pxe 63pxe\n",
      "n5cw7 n5cm7\n",
      "xd5fn w52fn\n",
      "4ypef 4ycex\n",
      "yge7c yge7c\n",
      "5xm8y 56m6y\n",
      "e46yw e46yw\n",
      "gwc3y gnc3n\n",
      "bxme8 pxne8\n",
      "x8edn x8e8n\n",
      "pcm7f pcm7f\n",
      "n2c85 n2c85\n",
      "cx8ey xxney\n",
      "nbdw3 nn6w6\n",
      "mfcgb nbcgb\n",
      "4cnwb 4cn7b\n",
      "n2y8p n2gmg\n",
      "m24fx m3wfw\n",
      "y3p58 y3c58\n",
      "pb37n pp87n\n",
      "gy8xb gy8xb\n",
      "mnfx3 nnfx3\n",
      "x3deb x3deb\n",
      "ge5pn gm6nn\n",
      "f6xg8 f6ww8\n",
      "8cfm4 8bbm4\n",
      "e6m5p e6m6p\n",
      "f85y3 f85y3\n",
      "m6f2p b6f2p\n",
      "y7x8e y7x8p\n",
      "78ndg f8f8g\n",
      "y32b4 y32yy\n",
      "cpdme cndmc\n",
      "3yb4f 3ym7f\n",
      "befyd befbd\n",
      "w6ybe w6yne\n",
      "f5cm2 f5cm2\n",
      "nfx3c gfxcc\n",
      "4753c f753f\n",
      "nfdb5 nfcb5\n",
      "3nfpw 3nnpw\n",
      "bc8nf bc8nf\n",
      "ewnx8 ewnx8\n",
      "d5nfw d666m\n",
      "gpf85 gnf85\n",
      "g284w g2fnw\n",
      "bym82 byc82\n",
      "xmd3y xnd3y\n",
      "gc4xn gpnxn\n",
      "dbmp5 deep5\n",
      "5x5n2 5x5nx\n",
      "2x4fg 2x7bm\n",
      "bwn5e pwn5e\n",
      "b5gf7 b5nmm\n",
      "nfd8g nfd8g\n",
      "7d6e3 7dgc2\n",
      "d2ycw d2ycw\n",
      "x3dwb x3fwf\n",
      "m3xfg n3xfg\n",
      "2enfy 2enf4\n",
      "fp7w2 fp762\n",
      "5yfgn byfgn\n",
      "4m2w5 4m2w5\n",
      "8gw74 8w754\n",
      "p5bce p5nce\n",
      "m3fd8 m4fd8\n",
      "nx2y5 d22y5\n",
      "n7ecx mn5c4\n",
      "fymn6 wwmn6\n",
      "my84c my84e\n",
      "467d5 467d5\n",
      "dfcne ddcne\n",
      "fbc4e nbp3e\n",
      "pmd3y pmd3w\n",
      "fcey3 fcey3\n",
      "wcgp7 w2yp7\n",
      "n3bm6 n3bm6\n",
      "n26my n265y\n",
      "5p2d4 bp2d4\n",
      "e5xf8 nxxf8\n",
      "x4f7p x4f7g\n",
      "n376x n3m6x\n",
      "n8dw4 gegw4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for e, f in zip(pred_test, labels_test):\n",
    "    print(e, f)\n",
    "    if e == f:\n",
    "        correct += 1\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27611940298507465"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/len(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
